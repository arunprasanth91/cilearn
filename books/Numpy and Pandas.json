{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nlist is very slow to process in python \\nso we use numpy which is an array \\nthis is stored at one continous space in memory which is why 50x faster \\narray obj in numpy is called ndarray\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#numpy stands for numerical python \n",
    "\"\"\"\n",
    "list is very slow to process in python \n",
    "so we use numpy which is an array \n",
    "this is stored at one continous space in memory which is why 50x faster \n",
    "array obj in numpy is called ndarray\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr= np.array([1,2,3,4,5])\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1\n"
     ]
    }
   ],
   "source": [
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int32')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#0D\n",
    "arr = np.array(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(42)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1D\n",
    "arr = np.array([1,2,3])\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2D\n",
    "arr = np.array([[1,2,3],[4,5,6]])\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check dimensions\n",
    "arr.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr = np.array([1,2,3,4,5],ndmin=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[[1, 2, 3, 4, 5]]]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "#Array indexing\n",
    "arr = np.array([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]])\n",
    "\n",
    "print(arr[0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 8 9]\n"
     ]
    }
   ],
   "source": [
    "# Array slicing\n",
    "arr = np.array([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n",
    "#1st parameter is the array subset and 2nd parameter is the element position\n",
    "print(arr[1, 1:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr1 = np.arange(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
       "       20, 21, 22])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr1 + 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    1,    8,   27,   64,  125,  216,  343,  512,  729, 1000,\n",
       "       1331, 1728, 2197, 2744, 3375, 4096, 4913, 5832, 6859], dtype=int32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr1 ** 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(arr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr2 = np.arange(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
       "       [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr2.reshape(2,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr2.sum(axis=0,keepdims=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr2.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6],\n",
       "       [7, 8, 9]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr3 = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "arr3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12, 15, 18])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr3.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(arr3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(arr3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy.random import randn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr4 = randn(5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.5150702 , -0.33278953,  0.51859406,  0.76003884, -0.0906856 ],\n",
       "       [-1.10180874,  2.00461094,  1.14469671, -0.76818594,  0.69637435],\n",
       "       [-0.73882476,  0.9322723 ,  1.46161655,  0.53593095,  0.51618991],\n",
       "       [-0.54179001,  0.42671175,  2.14391186, -0.20647189,  1.2579505 ],\n",
       "       [ 0.22678632, -0.22835506,  1.81422331, -1.28111693,  2.38617636]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr5 = randn(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr6 = randn(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.86170686, -1.58770775, -1.17008656, -1.46609846, -0.45077965,\n",
       "        0.33172483,  1.48270615, -0.47371926, -1.46864652, -0.14443412,\n",
       "       -1.0999199 ,  0.02284981,  0.9958526 , -0.13969925,  1.12050476,\n",
       "       -0.10458552,  0.37625227,  0.67460443, -1.02970395, -1.14426398,\n",
       "        0.33213941,  0.55721979,  0.06610884, -0.73877367, -2.21254341,\n",
       "        0.86730644,  1.51572734, -0.44299776, -0.05509784, -2.17440183])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.29015864,  0.95660719,  1.63173868,  0.1395724 , -0.6423411 ,\n",
       "        0.39075105, -1.5307085 ,  0.40513997,  1.72758363,  0.95707955,\n",
       "       -0.26773169, -1.65053189, -0.24809231, -0.41853553, -0.15515141,\n",
       "        0.59852733, -0.18257113,  0.12924636, -1.85160258, -0.30472032,\n",
       "       -0.3495992 , -1.10800483,  0.03495863,  0.66675111,  1.099451  ,\n",
       "       -0.34040474, -0.97312257, -2.77830019,  0.49846156, -0.49732718])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "answer = [(True if a_val > b_val else False) for a_val, b_val in zip(arr5,arr6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.29015864,  0.        ,  0.        ,  0.        , -0.6423411 ,\n",
       "        0.        , -1.5307085 ,  0.        ,  0.        ,  0.        ,\n",
       "       -0.26773169, -1.65053189, -0.24809231, -0.41853553, -0.15515141,\n",
       "        0.        , -0.18257113,  0.        , -1.85160258, -0.30472032,\n",
       "       -0.3495992 , -1.10800483,  0.        ,  0.        ,  0.        ,\n",
       "       -0.34040474, -0.97312257, -2.77830019,  0.        , -0.49732718])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(arr5>0,0,arr5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "countries = np.array(['France', 'Germany', 'USA', 'Russia','USA','Mexico','Germany'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['France', 'Germany', 'Mexico', 'Russia', 'USA'], \n",
       "      dtype='<U7')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.86170686, -1.58770775, -1.17008656, -1.46609846, -0.45077965,\n",
       "        0.33172483,  1.48270615, -0.47371926, -1.46864652, -0.14443412,\n",
       "       -1.0999199 ,  0.02284981,  0.9958526 , -0.13969925,  1.12050476,\n",
       "       -0.10458552,  0.37625227,  0.67460443, -1.02970395, -1.14426398,\n",
       "        0.33213941,  0.55721979,  0.06610884, -0.73877367, -2.21254341,\n",
       "        0.86730644,  1.51572734, -0.44299776, -0.05509784, -2.17440183])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('arr6',arr6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr6 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.86170686, -1.58770775, -1.17008656, -1.46609846, -0.45077965,\n",
       "        0.33172483,  1.48270615, -0.47371926, -1.46864652, -0.14443412,\n",
       "       -1.0999199 ,  0.02284981,  0.9958526 , -0.13969925,  1.12050476,\n",
       "       -0.10458552,  0.37625227,  0.67460443, -1.02970395, -1.14426398,\n",
       "        0.33213941,  0.55721979,  0.06610884, -0.73877367, -2.21254341,\n",
       "        0.86730644,  1.51572734, -0.44299776, -0.05509784, -2.17440183])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('arr6.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('arr.npz',arr5,np.load('arr6.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'Algorithms.ipynb',\n",
       " 'arr.npz.npy',\n",
       " 'arr.zip.npy',\n",
       " 'arr6.npy',\n",
       " 'basics.ipynb',\n",
       " 'data.json',\n",
       " 'Exercise.ipynb',\n",
       " 'french_words.csv',\n",
       " 'hangman.ipynb',\n",
       " 'intermediate.json',\n",
       " 'Numpy.ipynb',\n",
       " 'python.ipynb',\n",
       " 'python.json',\n",
       " 'regularexp.ipynb',\n",
       " 'sample.txt',\n",
       " 'utils.json']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.29015864,  0.95660719,  1.63173868,  0.1395724 , -0.6423411 ,\n",
       "        0.39075105, -1.5307085 ,  0.40513997,  1.72758363,  0.95707955,\n",
       "       -0.26773169, -1.65053189, -0.24809231, -0.41853553, -0.15515141,\n",
       "        0.59852733, -0.18257113,  0.12924636, -1.85160258, -0.30472032,\n",
       "       -0.3495992 , -1.10800483,  0.03495863,  0.66675111,  1.099451  ,\n",
       "       -0.34040474, -0.97312257, -2.77830019,  0.49846156, -0.49732718])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('arr.zip.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('arr.npz',arr5,np.load('arr6.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'Algorithms.ipynb',\n",
       " 'arr.npz.npy',\n",
       " 'arr.zip.npy',\n",
       " 'arr6.npy',\n",
       " 'basics.ipynb',\n",
       " 'data.json',\n",
       " 'Exercise.ipynb',\n",
       " 'french_words.csv',\n",
       " 'hangman.ipynb',\n",
       " 'intermediate.json',\n",
       " 'Numpy.ipynb',\n",
       " 'python.ipynb',\n",
       " 'python.json',\n",
       " 'regularexp.ipynb',\n",
       " 'sample.txt',\n",
       " 'utils.json']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'arr.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-99-12cc769baaa1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'arr.npz'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    368\u001b[0m     \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 370\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    371\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mis_pathlib_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'arr.npz'"
     ]
    }
   ],
   "source": [
    "np.load('arr.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savez('arr.npz',x=arr5,y=np.load('arr6.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'Algorithms.ipynb',\n",
       " 'arr.npz',\n",
       " 'arr.npz.npy',\n",
       " 'arr.zip.npy',\n",
       " 'arr6.npy',\n",
       " 'basics.ipynb',\n",
       " 'data.json',\n",
       " 'Exercise.ipynb',\n",
       " 'french_words.csv',\n",
       " 'hangman.ipynb',\n",
       " 'intermediate.json',\n",
       " 'Numpy.ipynb',\n",
       " 'python.ipynb',\n",
       " 'python.json',\n",
       " 'regularexp.ipynb',\n",
       " 'sample.txt',\n",
       " 'utils.json']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "archival = np.load('arr.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.29015864,  0.95660719,  1.63173868,  0.1395724 , -0.6423411 ,\n",
       "        0.39075105, -1.5307085 ,  0.40513997,  1.72758363,  0.95707955,\n",
       "       -0.26773169, -1.65053189, -0.24809231, -0.41853553, -0.15515141,\n",
       "        0.59852733, -0.18257113,  0.12924636, -1.85160258, -0.30472032,\n",
       "       -0.3495992 , -1.10800483,  0.03495863,  0.66675111,  1.099451  ,\n",
       "       -0.34040474, -0.97312257, -2.77830019,  0.49846156, -0.49732718])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "archival['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.86170686, -1.58770775, -1.17008656, -1.46609846, -0.45077965,\n",
       "        0.33172483,  1.48270615, -0.47371926, -1.46864652, -0.14443412,\n",
       "       -1.0999199 ,  0.02284981,  0.9958526 , -0.13969925,  1.12050476,\n",
       "       -0.10458552,  0.37625227,  0.67460443, -1.02970395, -1.14426398,\n",
       "        0.33213941,  0.55721979,  0.06610884, -0.73877367, -2.21254341,\n",
       "        0.86730644,  1.51572734, -0.44299776, -0.05509784, -2.17440183])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "archival['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-ad1b00255cd6>, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-ad1b00255cd6>\"\u001b[1;36m, line \u001b[1;32m11\u001b[0m\n\u001b[1;33m    0     3\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from pandas import Series,DataFrame\n",
    "import pandas as pd\n",
    "#Lets create a Series (array of data and data labels, its index)\n",
    "\n",
    "obj = Series([3,6,9,12])\n",
    "\n",
    "#Show\n",
    "obj\n",
    "0     3\n",
    "1     6\n",
    "2     9\n",
    "3    12\n",
    "dtype: int64\n",
    "#Lets show the values\n",
    "obj.values\n",
    "array([ 3,  6,  9, 12], dtype=int64)\n",
    "#Lets show the index\n",
    "obj.index\n",
    "Int64Index([0, 1, 2, 3], dtype='int64')\n",
    "#Now lets create a Series with an index\n",
    "\n",
    "#WW2 casualties \n",
    "ww2_cas = Series([8700000,4300000,3000000,2100000,400000],index=['USSR','Germany','China','Japan','USA'])\n",
    "\n",
    "#Show\n",
    "ww2_cas\n",
    "USSR       8700000\n",
    "Germany    4300000\n",
    "China      3000000\n",
    "Japan      2100000\n",
    "USA         400000\n",
    "dtype: int64\n",
    "#Now we can use index values to select Series values\n",
    "ww2_cas['USA']\n",
    "400000\n",
    "#Can also check with array operations\n",
    "\n",
    "#Check who had casualties greater than 4 million\n",
    "ww2_cas[ww2_cas>4000000]\n",
    "USSR       8700000\n",
    "Germany    4300000\n",
    "dtype: int64\n",
    "#Can treat Series as ordered dictionary\n",
    "\n",
    "#Check if USSR is in Series\n",
    "'USSR' in ww2_cas\n",
    "True\n",
    "#Can convert Series into Python dictionary\n",
    "ww2_dict = ww2_cas.to_dict()\n",
    "\n",
    "#Show\n",
    "ww2_dict\n",
    "{'China': 3000000,\n",
    " 'Germany': 4300000,\n",
    " 'Japan': 2100000,\n",
    " 'USA': 400000,\n",
    " 'USSR': 8700000}\n",
    "#Can convert back into a Series\n",
    "WW2_Series = Series(ww2_dict)\n",
    "#Show\n",
    "WW2_Series\n",
    "China      3000000\n",
    "Germany    4300000\n",
    "Japan      2100000\n",
    "USA         400000\n",
    "USSR       8700000\n",
    "dtype: int64\n",
    "#Passing a dictionary the index will have the dict keys in order\n",
    "countries = ['China','Germany','Japan','USA','USSR','Argentina']\n",
    "#Lets redefine a Series\n",
    "obj2 = Series(ww2_dict,index=countries)\n",
    "#Show\n",
    "obj2\n",
    "China        3000000\n",
    "Germany      4300000\n",
    "Japan        2100000\n",
    "USA           400000\n",
    "USSR         8700000\n",
    "Argentina        NaN\n",
    "dtype: float64\n",
    "#We can use isnull and notnull to find missing data\n",
    "pd.isnull(obj2)\n",
    "\n",
    "#obj2.isnull() \n",
    "China        False\n",
    "Germany      False\n",
    "Japan        False\n",
    "USA          False\n",
    "USSR         False\n",
    "Argentina     True\n",
    "dtype: bool\n",
    "#Same for the opposite\n",
    "pd.notnull(obj2)\n",
    "\n",
    "#obj2.notnull()\n",
    "China         True\n",
    "Germany       True\n",
    "Japan         True\n",
    "USA           True\n",
    "USSR          True\n",
    "Argentina    False\n",
    "dtype: bool\n",
    "#Lets see the ww2 Series again\n",
    "WW2_Series\n",
    "China      3000000\n",
    "Germany    4300000\n",
    "Japan      2100000\n",
    "USA         400000\n",
    "USSR       8700000\n",
    "dtype: int64\n",
    "#Lets check our Series with Argentine again\n",
    "obj2\n",
    "China        3000000\n",
    "Germany      4300000\n",
    "Japan        2100000\n",
    "USA           400000\n",
    "USSR         8700000\n",
    "Argentina        NaN\n",
    "dtype: float64\n",
    "#Now we can add and pandas automatically aligns data by index\n",
    "WW2_Series + obj2\n",
    "Argentina         NaN\n",
    "China         6000000\n",
    "Germany       8600000\n",
    "Japan         4200000\n",
    "USA            800000\n",
    "USSR         17400000\n",
    "dtype: float64\n",
    "#We can give Series names\n",
    "obj2.name = \"World War 2 Casualties\"\n",
    "#Show\n",
    "obj2\n",
    "China        3000000\n",
    "Germany      4300000\n",
    "Japan        2100000\n",
    "USA           400000\n",
    "USSR         8700000\n",
    "Argentina        NaN\n",
    "Name: World War 2 Casualties, dtype: float64\n",
    "#We can also name index\n",
    "obj2.index.name = 'Countries'\n",
    "#Show\n",
    "obj2\n",
    "Countries\n",
    "China        3000000\n",
    "Germany      4300000\n",
    "Japan        2100000\n",
    "USA           400000\n",
    "USSR         8700000\n",
    "Argentina        NaN\n",
    "Name: World War 2 Casualties, dtype: float64\n",
    "#Next we'll learn DataFrames!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-007dcf6a3a5c>, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-007dcf6a3a5c>\"\u001b[1;36m, line \u001b[1;32m15\u001b[0m\n\u001b[1;33m    Rank\tTeam\tWon\tLost\tTied*\tPct.\tFirst Season\tTotal Games\tConference\u001b[0m\n\u001b[1;37m        \t   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pandas import Series, DataFrame\n",
    "import pandas as pd\n",
    "#Now we'll learn DataFrames\n",
    "\n",
    "#Let's get some data to play with. How about the NFL?\n",
    "import webbrowser\n",
    "website = 'http://en.wikipedia.org/wiki/NFL_win-loss_records'\n",
    "webbrowser.open(website)\n",
    "True\n",
    "#Copy and read to get data\n",
    "nfl_frame = pd.read_clipboard()\n",
    "#Show\n",
    "nfl_frame\n",
    "Rank\tTeam\tWon\tLost\tTied*\tPct.\tFirst Season\tTotal Games\tConference\n",
    "0\t1\tDallas Cowboys\t510\t378\t6\t0.574\t1960\t894\tNFC East\n",
    "1\t2\tChicago Bears\t752\t563\t42\t0.570\t1920\t1357\tNFC North\n",
    "2\t3\tGreen Bay Packers\t741\t561\t37\t0.567\t1921\t1339\tNFC North\n",
    "3\t4\tMiami Dolphins\t443\t345\t4\t0.562\t1966\t792\tAFC East\n",
    "4\t5\tBaltimore Ravens\t182\t143\t1\t0.560\t1996\t326\tAFC North\n",
    "# We can grab the oclumn names with .columns\n",
    "nfl_frame.columns\n",
    "Index([u'Rank', u'Team', u'Won', u'Lost', u'Tied*', u'Pct.', u'First Season', u'Total Games', u'Conference'], dtype='object')\n",
    "#Lets see some specific data columns\n",
    "DataFrame(nfl_frame,columns=['Team','First Season','Total Games'])\n",
    "Team\tFirst Season\tTotal Games\n",
    "0\tDallas Cowboys\t1960\t894\n",
    "1\tChicago Bears\t1920\t1357\n",
    "2\tGreen Bay Packers\t1921\t1339\n",
    "3\tMiami Dolphins\t1966\t792\n",
    "4\tBaltimore Ravens\t1996\t326\n",
    "5\tSan Francisco 49ers\t1950\t1003\n",
    "#What happens if we ask for a column that doesn't exist?\n",
    "DataFrame(nfl_frame,columns=['Team','First Season','Total Games','Stadium'])\n",
    "Team\tFirst Season\tTotal Games\tStadium\n",
    "0\tDallas Cowboys\t1960\t894\t0\n",
    "1\tChicago Bears\t1920\t1357\t1\n",
    "2\tGreen Bay Packers\t1921\t1339\t2\n",
    "3\tMiami Dolphins\t1966\t792\t3\n",
    "4\tBaltimore Ravens\t1996\t326\t4\n",
    "# Call columns\n",
    "nfl_frame.columns\n",
    "Index([u'Rank', u'Team', u'Won', u'Lost', u'Tied*', u'Pct.', u'First Season', u'Total Games', u'Conference', u'Stadium'], dtype='object')\n",
    "#We can retrieve individual columns\n",
    "nfl_frame.Team\n",
    "0       Dallas Cowboys\n",
    "1        Chicago Bears\n",
    "2    Green Bay Packers\n",
    "3       Miami Dolphins\n",
    "4     Baltimore Ravens\n",
    "Name: Team, dtype: object\n",
    "# Or try this method for multiple word columns\n",
    "nfl_frame['Total Games']\n",
    "0     894\n",
    "1    1357\n",
    "2    1339\n",
    "3     792\n",
    "4     326\n",
    "Name: Total Games, dtype: int64\n",
    "#We can retrieve rows through indexing\n",
    "nfl_frame.ix[3]\n",
    "Rank                         4\n",
    "Team            Miami Dolphins\n",
    "Won                        443\n",
    "Lost                       345\n",
    "Tied*                        4\n",
    "Pct.                     0.562\n",
    "First Season              1966\n",
    "Total Games                792\n",
    "Conference            AFC East\n",
    "Name: 3, dtype: object\n",
    "#We can also assign value sto entire columns\n",
    "nfl_frame['Stadium']=\"Levi's Stadium\" #Careful with the ' here\n",
    "nfl_frame\n",
    "Rank\tTeam\tWon\tLost\tTied*\tPct.\tFirst Season\tTotal Games\tConference\tStadium\n",
    "0\t1\tDallas Cowboys\t510\t378\t6\t0.574\t1960\t894\tNFC East\tLevi's Stadium\n",
    "1\t2\tChicago Bears\t752\t563\t42\t0.570\t1920\t1357\tNFC North\tLevi's Stadium\n",
    "2\t3\tGreen Bay Packers\t741\t561\t37\t0.567\t1921\t1339\tNFC North\tLevi's Stadium\n",
    "3\t4\tMiami Dolphins\t443\t345\t4\t0.562\t1966\t792\tAFC East\tLevi's Stadium\n",
    "4\t5\tBaltimore Ravens\t182\t143\t1\t0.560\t1996\t326\tAFC North\tLevi's Stadium\n",
    "5\t6\tSan Francisco 49ers\t545\t444\t14\t0.550\t1950\t1003\tNFC West\tLevi's Stadium\n",
    "#Putting numbers for stadiums\n",
    "nfl_frame[\"Stadium\"] = np.arange(5)\n",
    "\n",
    "#Show\n",
    "nfl_frame\n",
    "Rank\tTeam\tWon\tLost\tTied*\tPct.\tFirst Season\tTotal Games\tConference\tStadium\n",
    "0\t1\tDallas Cowboys\t510\t378\t6\t0.574\t1960\t894\tNFC East\t0\n",
    "1\t2\tChicago Bears\t752\t563\t42\t0.570\t1920\t1357\tNFC North\t1\n",
    "2\t3\tGreen Bay Packers\t741\t561\t37\t0.567\t1921\t1339\tNFC North\t2\n",
    "3\t4\tMiami Dolphins\t443\t345\t4\t0.562\t1966\t792\tAFC East\t3\n",
    "4\t5\tBaltimore Ravens\t182\t143\t1\t0.560\t1996\t326\tAFC North\t4\n",
    "# Call columns\n",
    "nfl_frame.columns\n",
    "Index([u'Rank', u'Team', u'Won', u'Lost', u'Tied*', u'Pct.', u'First Season', u'Total Games', u'Conference', u'Stadium'], dtype='object')\n",
    "#Adding a Series to a DataFrame\n",
    "stadiums = Series([\"Levi's Stadium\",\"AT&T Stadium\"],index=[4,0])\n",
    "#Now input into the nfl DataFrame\n",
    "nfl_frame['Stadium']=stadiums\n",
    "\n",
    "#Show\n",
    "nfl_frame\n",
    "Rank\tTeam\tWon\tLost\tTied*\tPct.\tFirst Season\tTotal Games\tConference\tStadium\n",
    "0\t1\tDallas Cowboys\t510\t378\t6\t0.574\t1960\t894\tNFC East\tAT&T Stadium\n",
    "1\t2\tChicago Bears\t752\t563\t42\t0.570\t1920\t1357\tNFC North\tNaN\n",
    "2\t3\tGreen Bay Packers\t741\t561\t37\t0.567\t1921\t1339\tNFC North\tNaN\n",
    "3\t4\tMiami Dolphins\t443\t345\t4\t0.562\t1966\t792\tAFC East\tNaN\n",
    "4\t5\tBaltimore Ravens\t182\t143\t1\t0.560\t1996\t326\tAFC North\tLevi's Stadium\n",
    "#We can also delete columns\n",
    "del nfl_frame['Stadium']\n",
    "\n",
    "nfl_frame\n",
    "Rank\tTeam\tWon\tLost\tTied*\tPct.\tFirst Season\tTotal Games\tConference\n",
    "0\t1\tDallas Cowboys\t510\t378\t6\t0.574\t1960\t894\tNFC East\n",
    "1\t2\tChicago Bears\t752\t563\t42\t0.570\t1920\t1357\tNFC North\n",
    "2\t3\tGreen Bay Packers\t741\t561\t37\t0.567\t1921\t1339\tNFC North\n",
    "3\t4\tMiami Dolphins\t443\t345\t4\t0.562\t1966\t792\tAFC East\n",
    "4\t5\tBaltimore Ravens\t182\t143\t1\t0.560\t1996\t326\tAFC North\n",
    "#DataFrames can be constructed many ways. Another way is from a dictionary of equal length lists\n",
    "data = {'City':['SF','LA','NYC'],\n",
    "        'Population':[837000,3880000,8400000]}\n",
    "\n",
    "city_frame = DataFrame(data)\n",
    "\n",
    "#Show\n",
    "city_frame\n",
    "City\tPopulation\n",
    "0\tSF\t837000\n",
    "1\tLA\t3880000\n",
    "2\tNYC\t8400000\n",
    "#For full list of ways to create DataFrames from various sources go to teh documentation for pandas:\n",
    "website = 'http://pandas.pydata.org/pandas-docs/dev/generated/pandas.DataFrame.html'\n",
    "webbrowser.open(website)\n",
    "True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-506ddbc758c5>, line 19)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-506ddbc758c5>\"\u001b[1;36m, line \u001b[1;32m19\u001b[0m\n\u001b[1;33m    ---------------------------------------------------------------------------\u001b[0m\n\u001b[1;37m                                                                               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from pandas import Series,DataFrame\n",
    "\n",
    "import pandas as pd\n",
    "#Let's learn/review about Index Objects\n",
    "my_ser = Series([1,2,3,4],index=['A','B','C','D'])\n",
    "\n",
    "#Get the index\n",
    "my_index = my_ser.index\n",
    "#Show\n",
    "my_index\n",
    "Index([u'a', u'b', u'c', u'd'], dtype='object')\n",
    "#Can grab index ranges\n",
    "my_index[2:]\n",
    "Index([u'C', u'D'], dtype='object')\n",
    "#What happens if we try to change an index value?\n",
    "my_index[0] = 'Z'\n",
    "---------------------------------------------------------------------------\n",
    "TypeError                                 Traceback (most recent call last)\n",
    "<ipython-input-8-599f591f1af8> in <module>()\n",
    "      1 #What happens if we try to change an index value?\n",
    "----> 2 my_index[0] = 'Z'\n",
    "\n",
    "C:\\Users\\Marcial\\Anaconda\\lib\\site-packages\\pandas\\core\\index.pyc in __setitem__(self, key, value)\n",
    "    894 \n",
    "    895     def __setitem__(self, key, value):\n",
    "--> 896         raise TypeError(\"Indexes does not support mutable operations\")\n",
    "    897 \n",
    "    898     def __getitem__(self, key):\n",
    "\n",
    "TypeError: Indexes does not support mutable operations\n",
    "#Excellent! Indexes are immutable!\n",
    "#Next we'll learn about Reindexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-dc442308acf6>, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-4-dc442308acf6>\"\u001b[1;36m, line \u001b[1;32m10\u001b[0m\n\u001b[1;33m    A    1\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#Now we'll elarn about reindexing\n",
    "import numpy as np\n",
    "from pandas import Series, DataFrame\n",
    "import pandas as pd\n",
    "from numpy.random import randn\n",
    "#Lets create a new series\n",
    "ser1 = Series([1,2,3,4],index=['A','B','C','D'])\n",
    "#Show\n",
    "ser1\n",
    "A    1\n",
    "B    2\n",
    "C    3\n",
    "D    4\n",
    "dtype: int64\n",
    "#Call reindex to rearrange the data to a new index\n",
    "ser2 = ser1.reindex(['A','B','C','D','E','F'])\n",
    "#Show\n",
    "ser2\n",
    "A     1\n",
    "B     2\n",
    "C     3\n",
    "D     4\n",
    "E   NaN\n",
    "F   NaN\n",
    "dtype: float64\n",
    "# We can alos fill in values for new indexes\n",
    "ser2.reindex(['A','B','C','D','E','F','G'],fill_value=0)\n",
    "A     1\n",
    "B     2\n",
    "C     3\n",
    "D     4\n",
    "E   NaN\n",
    "F   NaN\n",
    "G     0\n",
    "dtype: float64\n",
    "#Using a particular method for filling values\n",
    "ser3 = Series(['USA','Mexico','Canada'],index=[0,5,10])\n",
    "\n",
    "#Show\n",
    "ser3\n",
    "0        USA\n",
    "5     Mexico\n",
    "10    Canada\n",
    "dtype: object\n",
    "#Can use a forward fill for interploating values vetween indices \n",
    "ser3.reindex(range(15),method='ffill')\n",
    "0        USA\n",
    "1        USA\n",
    "2        USA\n",
    "3        USA\n",
    "4        USA\n",
    "5     Mexico\n",
    "6     Mexico\n",
    "7     Mexico\n",
    "8     Mexico\n",
    "9     Mexico\n",
    "10    Canada\n",
    "11    Canada\n",
    "12    Canada\n",
    "13    Canada\n",
    "14    Canada\n",
    "dtype: object\n",
    "#Reindexing rows, columns or both\n",
    "\n",
    "#Lets make a datafram ewith some random values\n",
    "dframe = DataFrame(randn(25).reshape((5,5)),index=['A','B','D','E','F'],columns=['col1','col2','col3','col4','col5'])\n",
    "\n",
    "#Show\n",
    "dframe\n",
    "#Notice we forgot 'C' , lets reindex it into dframe\n",
    "dframe2 = dframe.reindex(['A','B','C','D','E','F'])\n",
    "#Can also explicitly reindex columns\n",
    "new_columns = ['col1','col2','col3','col4','col5','col6']\n",
    "\n",
    "dframe2.reindex(columns=new_columns)\n",
    "col1\tcol2\tcol3\tcol4\tcol5\tcol6\n",
    "A\t0.442886\t0.128326\t0.091837\t0.018814\t-1.419262\tNaN\n",
    "B\t0.650227\t0.438677\t-0.208091\t1.263344\t0.147084\tNaN\n",
    "C\tNaN\tNaN\tNaN\tNaN\tNaN\tNaN\n",
    "D\t-1.089677\t1.616700\t1.856270\t0.553392\t1.046027\tNaN\n",
    "E\t0.608385\t-0.316224\t0.341510\t-0.085305\t1.015604\tNaN\n",
    "F\t1.054495\t-0.274723\t1.251613\t0.160329\t-0.527855\tNaN\n",
    "#Reindex quickly using the label-indexing with ix (we'll see this more in the future)\n",
    "\n",
    "#Show original\n",
    "dframe\n",
    "col1\tcol2\tcol3\tcol4\tcol5\n",
    "A\t0.442886\t0.128326\t0.091837\t0.018814\t-1.419262\n",
    "B\t0.650227\t0.438677\t-0.208091\t1.263344\t0.147084\n",
    "D\t-1.089677\t1.616700\t1.856270\t0.553392\t1.046027\n",
    "E\t0.608385\t-0.316224\t0.341510\t-0.085305\t1.015604\n",
    "F\t1.054495\t-0.274723\t1.251613\t0.160329\t-0.527855\n",
    "dframe.ix[['A','B','C','D','E','F'],new_columns]\n",
    "col1\tcol2\tcol3\tcol4\tcol5\tcol6\n",
    "A\t0.442886\t0.128326\t0.091837\t0.018814\t-1.419262\tNaN\n",
    "B\t0.650227\t0.438677\t-0.208091\t1.263344\t0.147084\tNaN\n",
    "C\tNaN\tNaN\tNaN\tNaN\tNaN\tNaN\n",
    "D\t-1.089677\t1.616700\t1.856270\t0.553392\t1.046027\tNaN\n",
    "E\t0.608385\t-0.316224\t0.341510\t-0.085305\t1.015604\tNaN\n",
    "F\t1.054495\t-0.274723\t1.251613\t0.160329\t-0.527855\tNaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-63ef666d50b6>, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-5-63ef666d50b6>\"\u001b[1;36m, line \u001b[1;32m10\u001b[0m\n\u001b[1;33m    a    0\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#Now we'll learn about dropping entries\n",
    "import numpy as np\n",
    "from pandas import Series,DataFrame\n",
    "import pandas as pd\n",
    "#Create a new series to play with\n",
    "ser1 = Series(np.arange(3),index=['a','b','c'])\n",
    "\n",
    "#Show\n",
    "ser1\n",
    "a    0\n",
    "b    1\n",
    "c    2\n",
    "dtype: int32\n",
    "#Now let's drop an index\n",
    "ser1.drop('b')\n",
    "a    0\n",
    "c    2\n",
    "dtype: int32\n",
    "#With a DataFrame we can drop values from either axis\n",
    "dframe1 = DataFrame(np.arange(9).reshape((3,3)),index=['SF','LA','NY'],columns=['pop','size','year'])\n",
    "\n",
    "#Show (remember just random values)\n",
    "dframe1\n",
    "pop\tsize\tyear\n",
    "SF\t0\t1\t2\n",
    "LA\t3\t4\t5\n",
    "NY\t6\t7\t8\n",
    "#Now dropping a row\n",
    "dframe1.drop('LA')\n",
    "pop\tsize\tyear\n",
    "SF\t0\t1\t2\n",
    "NY\t6\t7\t8\n",
    "#Or we could drop a column\n",
    "\n",
    "#Need to specify that axis is 1, not 0\n",
    "dframe1.drop('year',axis=1)\n",
    "pop\tsize\n",
    "SF\t0\t1\n",
    "LA\t3\t4\n",
    "NY\t6\t7\n",
    "#Next we'll learn about selecting entires in a DataFrame!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-48c344c72df4>, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-6-48c344c72df4>\"\u001b[1;36m, line \u001b[1;32m13\u001b[0m\n\u001b[1;33m    A    0\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#Now we'll learn about Selecting Entries\n",
    "import numpy as np\n",
    "from pandas import Series,DataFrame\n",
    "import pandas as pd\n",
    "#Lets try some Series indexing\n",
    "ser1 = Series(np.arange(3),index=['A','B','C'])\n",
    "\n",
    "#multiply all values by 2, to avoid confusion in future\n",
    "ser1 = 2*ser1\n",
    "\n",
    "#Show\n",
    "ser1 \n",
    "A    0\n",
    "B    2\n",
    "C    4\n",
    "dtype: int32\n",
    "#Can grab entry by index name\n",
    "ser1['B']\n",
    "2\n",
    "#Or grab by index \n",
    "ser1[1]\n",
    "2\n",
    "#Can also grab by index range\n",
    "ser1[0:3]\n",
    "A    0\n",
    "B    2\n",
    "C    4\n",
    "dtype: int32\n",
    "#Or grab range by range of index values\n",
    "ser1[['A','B','C']]\n",
    "A    0\n",
    "B    2\n",
    "C    4\n",
    "dtype: int32\n",
    "#Or grab by logic\n",
    "ser1[ser1>3]\n",
    "C    4\n",
    "dtype: int32\n",
    "#Can also ser using these methods\n",
    "ser1[ser1>3] = 10\n",
    "\n",
    "#Show\n",
    "ser1\n",
    "A     0\n",
    "B     2\n",
    "C    10\n",
    "dtype: int32\n",
    "#Now let's see sleection in a DataFrame\n",
    "\n",
    "dframe = DataFrame(np.arange(25).reshape((5,5)),index=['NYC','LA','SF','DC','Chi'],columns=['A','B','C','D','E'])\n",
    "\n",
    "#Show\n",
    "dframe\n",
    "A\tB\tC\tD\tE\n",
    "NYC\t0\t1\t2\t3\t4\n",
    "LA\t5\t6\t7\t8\t9\n",
    "SF\t10\t11\t12\t13\t14\n",
    "DC\t15\t16\t17\t18\t19\n",
    "Chi\t20\t21\t22\t23\t24\n",
    "#Select by column name\n",
    "dframe['B']\n",
    "NYC     1\n",
    "LA      6\n",
    "SF     11\n",
    "DC     16\n",
    "Chi    21\n",
    "Name: B, dtype: int32\n",
    "#Select by multiple columns\n",
    "dframe[['B','E']]\n",
    "B\tE\n",
    "NYC\t1\t4\n",
    "LA\t6\t9\n",
    "SF\t11\t14\n",
    "DC\t16\t19\n",
    "Chi\t21\t24\n",
    "#Can also use boolean\n",
    "dframe[dframe['C']>8]\n",
    "A\tB\tC\tD\tE\n",
    "SF\t10\t11\t12\t13\t14\n",
    "DC\t15\t16\t17\t18\t19\n",
    "Chi\t20\t21\t22\t23\t24\n",
    "#Can also just shoe a boolean DataFrame\n",
    "dframe> 10\n",
    "A\tB\tC\tD\tE\n",
    "NYC\tFalse\tFalse\tFalse\tFalse\tFalse\n",
    "LA\tFalse\tFalse\tFalse\tFalse\tFalse\n",
    "SF\tFalse\tTrue\tTrue\tTrue\tTrue\n",
    "DC\tTrue\tTrue\tTrue\tTrue\tTrue\n",
    "Chi\tTrue\tTrue\tTrue\tTrue\tTrue\n",
    "#Can alos use ix as previously discussed to label-index\n",
    "dframe.ix['LA']\n",
    "A    5\n",
    "B    6\n",
    "C    7\n",
    "D    8\n",
    "E    9\n",
    "Name: LA, dtype: int32\n",
    "#Another example\n",
    "dframe.ix[1]\n",
    "A    5\n",
    "B    6\n",
    "C    7\n",
    "D    8\n",
    "E    9\n",
    "Name: LA, dtype: int32\n",
    "#Next we'll learn about data alignment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-66981792e42f>, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-66981792e42f>\"\u001b[1;36m, line \u001b[1;32m9\u001b[0m\n\u001b[1;33m    C    0\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pandas import Series,DataFrame\n",
    "import pandas as pd\n",
    "#Sorting by index\n",
    "ser1 = Series(range(3),index=['C','A','B'])\n",
    "\n",
    "#show\n",
    "ser1\n",
    "C    0\n",
    "A    1\n",
    "B    2\n",
    "dtype: int64\n",
    "#Now sort_index\n",
    "ser1.sort_index()\n",
    "A    1\n",
    "B    2\n",
    "C    0\n",
    "dtype: int64\n",
    "#Can sort a Series by its values\n",
    "ser1.order()\n",
    "C    0\n",
    "A    1\n",
    "B    2\n",
    "dtype: int64\n",
    "#Lets see how ranking works\n",
    "\n",
    "from numpy.random import randn\n",
    "ser2 = Series(randn(10))\n",
    "\n",
    "#Show\n",
    "ser2\n",
    "0    0.524553\n",
    "1   -1.987343\n",
    "2   -0.883902\n",
    "3   -0.875829\n",
    "4    0.216089\n",
    "5    0.744837\n",
    "6   -0.761465\n",
    "7    0.792798\n",
    "8   -0.144650\n",
    "9    0.100972\n",
    "dtype: float64\n",
    "#This will show you the rank used if you sort the series\n",
    "ser2.rank()\n",
    "0     8\n",
    "1     1\n",
    "2     2\n",
    "3     3\n",
    "4     7\n",
    "5     9\n",
    "6     4\n",
    "7    10\n",
    "8     5\n",
    "9     6\n",
    "dtype: float64\n",
    "#Lets sort it now\n",
    "ser2.sort()\n",
    "\n",
    "#Show\n",
    "ser2\n",
    "1   -1.987343\n",
    "2   -0.883902\n",
    "3   -0.875829\n",
    "6   -0.761465\n",
    "8   -0.144650\n",
    "9    0.100972\n",
    "4    0.216089\n",
    "0    0.524553\n",
    "5    0.744837\n",
    "7    0.792798\n",
    "dtype: float64\n",
    "#After sorting let's check the rank and see iof it makes sense\n",
    "ser2.rank()\n",
    "1     1\n",
    "2     2\n",
    "3     3\n",
    "6     4\n",
    "8     5\n",
    "9     6\n",
    "4     7\n",
    "0     8\n",
    "5     9\n",
    "7    10\n",
    "dtype: float64\n",
    "#On the left column we see th original index value and on the right we see it's rank!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-39966eb90dbb>, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-39966eb90dbb>\"\u001b[1;36m, line \u001b[1;32m9\u001b[0m\n\u001b[1;33m    q\tr\ts\tt\tapple\u001b[0m\n\u001b[1;37m     \t^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pandas import Series,DataFrame\n",
    "import pandas as pd\n",
    "# Can open csv files as a dataframe\n",
    "dframe = pd.read_csv('lec25.csv')\n",
    "\n",
    "#Show\n",
    "dframe\n",
    "q\tr\ts\tt\tapple\n",
    "0\t2\t3\t4\t5\tpear\n",
    "1\ta\ts\td\tf\trabbit\n",
    "2\t5\t2\t5\t7\tdog\n",
    "# Can also use read_table with ',' as a delimiter\n",
    "dframe = pd.read_table('lec25.csv',sep=',')\n",
    "\n",
    "#Show\n",
    "dframe\n",
    "q\tr\ts\tt\tapple\n",
    "0\t2\t3\t4\t5\tpear\n",
    "1\ta\ts\td\tf\trabbit\n",
    "2\t5\t2\t5\t7\tdog\n",
    "dframe\n",
    "q\tr\ts\tt\tapple\n",
    "0\t2\t3\t4\t5\tpear\n",
    "1\ta\ts\td\tf\trabbit\n",
    "2\t5\t2\t5\t7\tdog\n",
    "#If we dont want the header to be the first row\n",
    "dframe = pd.read_csv('lec25.csv',header=None)\n",
    "\n",
    "#Show\n",
    "dframe\n",
    "0\t1\t2\t3\t4\n",
    "0\tq\tr\ts\tt\tapple\n",
    "1\t2\t3\t4\t5\tpear\n",
    "2\ta\ts\td\tf\trabbit\n",
    "3\t5\t2\t5\t7\tdog\n",
    "# We can also indicate a particular number of rows to be read\n",
    "pd.read_csv('lec25.csv',header=None,nrows=2)\n",
    "0\t1\t2\t3\t4\n",
    "0\tq\tr\ts\tt\tapple\n",
    "1\t2\t3\t4\t5\tpear\n",
    "# Let's see dframe again\n",
    "dframe\n",
    "0\t1\t2\t3\t4\n",
    "0\tq\tr\ts\tt\tapple\n",
    "1\t2\t3\t4\t5\tpear\n",
    "2\ta\ts\td\tf\trabbit\n",
    "3\t5\t2\t5\t7\tdog\n",
    "# Now let's see how we can write DataFrames out to text files\n",
    "dframe.to_csv('mytextdata_out.csv')\n",
    "\n",
    "#You'll see this file where you're ipython Notebooks are saved (Usually under my documents)\n",
    "#  We can also use other delimiters\n",
    "\n",
    "#we'll import sys to see the output\n",
    "import sys \n",
    "\n",
    "#Use sys.stdout to see the output directly and not save it\n",
    "dframe.to_csv(sys.stdout,sep='_')\n",
    "_0_1_2_3_4\n",
    "0_q_r_s_t_apple\n",
    "1_2_3_4_5_pear\n",
    "2_a_s_d_f_rabbit\n",
    "3_5_2_5_7_dog\n",
    "# Just to make sure we understand the delimiter\n",
    "dframe.to_csv(sys.stdout,sep='?')\n",
    "?0?1?2?3?4\n",
    "0?q?r?s?t?apple\n",
    "1?2?3?4?5?pear\n",
    "2?a?s?d?f?rabbit\n",
    "3?5?2?5?7?dog\n",
    "#We can also choose to write only a specific subset of columns\n",
    "dframe.to_csv(sys.stdout,columns=[0,1,2])\n",
    ",0,1,2\n",
    "0,q,r,s\n",
    "1,2,3,4\n",
    "2,a,s,d\n",
    "3,5,2,5\n",
    "#You should also check out pythons built-in csv reader and writer for more info:\n",
    "# https://docs.python.org/2/library/csv.html\n",
    "  File \"<ipython-input-18-0b665ff54019>\", line 2\n",
    "    https://docs.python.org/2/library/csv.html\n",
    "         ^\n",
    "SyntaxError: invalid syntax\n",
    "#Next we'll learn about reading JSON data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-1c3b1cddc6c6>, line 32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-1c3b1cddc6c6>\"\u001b[1;36m, line \u001b[1;32m32\u001b[0m\n\u001b[1;33m    food\tfur\tzoo_animal\u001b[0m\n\u001b[1;37m        \t  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pandas import Series, DataFrame\n",
    "import pandas as pd\n",
    "# Heres an example of what a JSON (JavaScript Object Notation) looks like:\n",
    "json_obj = \"\"\"\n",
    "{   \"zoo_animal\": \"Lion\",\n",
    "    \"food\": [\"Meat\", \"Veggies\", \"Honey\"],\n",
    "    \"fur\": \"Golden\",\n",
    "    \"clothes\": null, \n",
    "    \"diet\": [{\"zoo_animal\": \"Gazelle\", \"food\":\"grass\", \"fur\": \"Brown\"}]\n",
    "}\n",
    "\"\"\"\n",
    "#Let import json module\n",
    "import json\n",
    "\n",
    "#Lets load json data\n",
    "data = json.loads(json_obj)\n",
    "#Show\n",
    "data\n",
    "{u'clothes': None,\n",
    " u'diet': [{u'food': u'grass', u'fur': u'Brown', u'zoo_animal': u'Gazelle'}],\n",
    " u'food': [u'Meat', u'Veggies', u'Honey'],\n",
    " u'fur': u'Golden',\n",
    " u'zoo_animal': u'Lion'}\n",
    "#WE can also convert back to JSON\n",
    "json.dumps(data)\n",
    "'{\"food\": [\"Meat\", \"Veggies\", \"Honey\"], \"zoo_animal\": \"Lion\", \"fur\": \"Golden\", \"diet\": [{\"food\": \"grass\", \"zoo_animal\": \"Gazelle\", \"fur\": \"Brown\"}], \"clothes\": null}'\n",
    "#We can simply open JSON data after loading with a DataFrame\n",
    "dframe = DataFrame(data['diet'])\n",
    "#Show\n",
    "dframe\n",
    "food\tfur\tzoo_animal\n",
    "0\tgrass\tBrown\tGazelle\n",
    "# Theres lost of custom selection you can do, based on what you do or dont want in your DataFrame (you can specify columns..etc)\n",
    "#Next up, XML and HTML file format with python!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-e5cfb973fe15>, line 19)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-4-e5cfb973fe15>\"\u001b[1;36m, line \u001b[1;32m19\u001b[0m\n\u001b[1;33m    Bank Name\tCity\tST\tCERT\tAcquiring Institution\tClosing Date\tUpdated Date\tLoss Share Type\tAgreement Terminated\tTermination Date\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# We can import data using lxml\n",
    "\n",
    "from pandas import read_html\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "#Lets grab a url for list of failed banks\n",
    "url = 'http://www.fdic.gov/bank/individual/failed/banklist.html'\n",
    "\"\"\"\n",
    "IMPORTANT NOTE: NEED TO HAVE beautiful-soup INSTALLED as well as html5lib !!!!\n",
    "\n",
    "\"\"\"\n",
    "'\\nIMPORTANT NOTE: NEED TO HAVE beautiful-soup INSTALLED as well as html5lib !!!!\\n\\n'\n",
    "# Grab data from html and put it intop a list of DataFrame objects!\n",
    "dframe_list = pd.io.html.read_html(url)\n",
    "#Grab the first list item from the data base and set as a DataFrame\n",
    "dframe = dframe_list[0]\n",
    "#Show\n",
    "dframe\n",
    "Bank Name\tCity\tST\tCERT\tAcquiring Institution\tClosing Date\tUpdated Date\tLoss Share Type\tAgreement Terminated\tTermination Date\n",
    "0\tCapitol City Bank & Trust Company\tAtlanta\tGA\t33938\tFirst-Citizens Bank & Trust Company\tFebruary 13, 2015\tFebruary 19, 2015\tnone\tNaN\tNaN\n",
    "1\tHighland Community Bank\tChicago\tIL\t20290\tUnited Fidelity Bank, fsb\tJanuary 23, 2015\tFebruary 11, 2015\tnone\tNaN\tNaN\n",
    "2\tFirst National Bank of Crestview\tCrestview\tFL\t17557\tFirst NBC Bank\tJanuary 16, 2015\tFebruary 11, 2015\tnone\tNaN\tNaN\n",
    "3\tNorthern Star Bank\tMankato\tMN\t34983\tBankVista\tDecember 19, 2014\tFebruary 4, 2015\tnone\tNaN\tNaN\n",
    "4\tFrontier Bank, FSB D/B/A El Paseo Bank\tPalm Desert\tCA\t34738\tBank of Southern California, N.A.\tNovember 7, 2014\tFebruary 4, 2015\tnone\tNaN\tNaN\n",
    "5\tThe National Republic Bank of Chicago\tChicago\tIL\t916\tState Bank of Texas\tOctober 24, 2014\tFebruary 4, 2015\tnone\tNaN\tNaN\n",
    "6\tNBRS Financial\tRising Sun\tMD\t4862\tHoward Bank\tOctober 17, 2014\tFebruary 4, 2015\tnone\tNaN\tNaN\n",
    "7\tGreenChoice Bank, fsb\tChicago\tIL\t28462\tProvidence Bank, LLC\tJuly 25, 2014\tJanuary 5, 2015\tnone\tNaN\tNaN\n",
    "8\tEastside Commercial Bank\tConyers\tGA\t58125\tCommunity & Southern Bank\tJuly 18, 2014\tJanuary 5, 2015\tnone\tNaN\tNaN\n",
    "9\tThe Freedom State Bank\tFreedom\tOK\t12483\tAlva State Bank & Trust Company\tJune 27, 2014\tJuly 18, 2014\tnone\tNaN\tNaN\n",
    "10\tValley Bank\tFort Lauderdale\tFL\t21793\tLandmark Bank, National Association\tJune 20, 2014\tJuly 28, 2014\tnone\tNaN\tNaN\n",
    "11\tValley Bank\tMoline\tIL\t10450\tGreat Southern Bank\tJune 20, 2014\tJuly 28, 2014\tnone\tNaN\tNaN\n",
    "12\tSlavie Federal Savings Bank\tBel Air\tMD\t32368\tBay Bank, FSB\tMay 30, 2014\tJuly 18, 2014\tnone\tNaN\tNaN\n",
    "13\tColumbia Savings Bank\tCincinnati\tOH\t32284\tUnited Fidelity Bank, fsb\tMay 23, 2014\tJuly 18, 2014\tnone\tNaN\tNaN\n",
    "14\tAztecAmerica Bank En Espanol\tBerwyn\tIL\t57866\tRepublic Bank of Chicago\tMay 16, 2014\tJuly 18, 2014\tnone\tNaN\tNaN\n",
    "15\tAllendale County Bank\tFairfax\tSC\t15062\tPalmetto State Bank\tApril 25, 2014\tJuly 18, 2014\tnone\tNaN\tNaN\n",
    "16\tVantage Point Bank\tHorsham\tPA\t58531\tFirst Choice Bank\tFebruary 28, 2014\tApril 11, 2014\tnone\tNaN\tNaN\n",
    "17\tMillennium Bank, National Association\tSterling\tVA\t35096\tWashingtonFirst Bank\tFebruary 28, 2014\tApril 11, 2014\tnone\tNaN\tNaN\n",
    "18\tSyringa Bank\tBoise\tID\t34296\tSunwest Bank\tJanuary 31, 2014\tFebruary 19, 2015\tnone\tNaN\tNaN\n",
    "19\tThe Bank of Union\tEl Reno\tOK\t17967\tBancFirst\tJanuary 24, 2014\tFebruary 19, 2015\tnone\tNaN\tNaN\n",
    "20\tDuPage National Bank\tWest Chicago\tIL\t5732\tRepublic Bank of Chicago\tJanuary 17, 2014\tFebruary 19, 2015\tnone\tNaN\tNaN\n",
    "21\tTexas Community Bank, National Association\tThe Woodlands\tTX\t57431\tSpirit of Texas Bank, SSB\tDecember 13, 2013\tDecember 29, 2014\tnone\tNaN\tNaN\n",
    "22\tBank of Jackson County\tGraceville\tFL\t14794\tFirst Federal Bank of Florida\tOctober 30, 2013\tNovember 05, 2014\tnone\tNaN\tNaN\n",
    "23\tFirst National Bank also operating as The Nat...\tEdinburg\tTX\t14318\tPlainsCapital Bank\tSeptember 13, 2013\tSeptember 12, 2014\tSFR/NSF\tNaN\tNaN\n",
    "24\tThe Community's Bank\tBridgeport\tCT\t57041\tNo Acquirer\tSeptember 13, 2013\tDecember 20, 2013\tnone\tNaN\tNaN\n",
    "25\tSunrise Bank of Arizona\tPhoenix\tAZ\t34707\tFirst Fidelity Bank, National Association\tAugust 23, 2013\tSeptember 12, 2014\tnone\tNaN\tNaN\n",
    "26\tCommunity South Bank\tParsons\tTN\t19849\tCB&S Bank, Inc.\tAugust 23, 2013\tSeptember 12, 2014\tnone\tNaN\tNaN\n",
    "27\tBank of Wausau\tWausau\tWI\t35016\tNicolet National Bank\tAugust 9, 2013\tOctober 24, 2013\tnone\tNaN\tNaN\n",
    "28\tFirst Community Bank of Southwest Florida (als...\tFort Myers\tFL\t34943\tC1 Bank\tAugust 2, 2013\tAugust 4, 2014\tnone\tNaN\tNaN\n",
    "29\tMountain National Bank\tSevierville\tTN\t34789\tFirst Tennessee Bank, National Association\tJune 7, 2013\tJune 20, 2014\tnone\tNaN\tNaN\n",
    "...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\n",
    "507\tANB Financial, NA\tBentonville\tAR\t33901\tPulaski Bank and Trust Company\tMay 9, 2008\tAugust 28, 2012\tnone\tNaN\tNaN\n",
    "508\tHume Bank\tHume\tMO\t1971\tSecurity Bank\tMarch 7, 2008\tAugust 28, 2012\tnone\tNaN\tNaN\n",
    "509\tDouglass National Bank\tKansas City\tMO\t24660\tLiberty Bank and Trust Company\tJanuary 25, 2008\tOctober 26, 2012\tnone\tNaN\tNaN\n",
    "510\tMiami Valley Bank\tLakeview\tOH\t16848\tThe Citizens Banking Company\tOctober 4, 2007\tAugust 28, 2012\tnone\tNaN\tNaN\n",
    "511\tNetBank\tAlpharetta\tGA\t32575\tING DIRECT\tSeptember 28, 2007\tAugust 28, 2012\tnone\tNaN\tNaN\n",
    "512\tMetropolitan Savings Bank\tPittsburgh\tPA\t35353\tAllegheny Valley Bank of Pittsburgh\tFebruary 2, 2007\tOctober 27, 2010\tnone\tNaN\tNaN\n",
    "513\tBank of Ephraim\tEphraim\tUT\t1249\tFar West Bank\tJune 25, 2004\tApril 9, 2008\tnone\tNaN\tNaN\n",
    "514\tReliance Bank\tWhite Plains\tNY\t26778\tUnion State Bank\tMarch 19, 2004\tApril 9, 2008\tnone\tNaN\tNaN\n",
    "515\tGuaranty National Bank of Tallahassee\tTallahassee\tFL\t26838\tHancock Bank of Florida\tMarch 12, 2004\tJune 5, 2012\tnone\tNaN\tNaN\n",
    "516\tDollar Savings Bank\tNewark\tNJ\t31330\tNo Acquirer\tFebruary 14, 2004\tApril 9, 2008\tnone\tNaN\tNaN\n",
    "517\tPulaski Savings Bank\tPhiladelphia\tPA\t27203\tEarthstar Bank\tNovember 14, 2003\tJuly 22, 2005\tnone\tNaN\tNaN\n",
    "518\tFirst National Bank of Blanchardville\tBlanchardville\tWI\t11639\tThe Park Bank\tMay 9, 2003\tJune 5, 2012\tnone\tNaN\tNaN\n",
    "519\tSouthern Pacific Bank\tTorrance\tCA\t27094\tBeal Bank\tFebruary 7, 2003\tOctober 20, 2008\tnone\tNaN\tNaN\n",
    "520\tFarmers Bank of Cheneyville\tCheneyville\tLA\t16445\tSabine State Bank & Trust\tDecember 17, 2002\tOctober 20, 2004\tnone\tNaN\tNaN\n",
    "521\tBank of Alamo\tAlamo\tTN\t9961\tNo Acquirer\tNovember 8, 2002\tMarch 18, 2005\tnone\tNaN\tNaN\n",
    "522\tAmTrade International BankEn Espanol\tAtlanta\tGA\t33784\tNo Acquirer\tSeptember 30, 2002\tSeptember 11, 2006\tnone\tNaN\tNaN\n",
    "523\tUniversal Federal Savings Bank\tChicago\tIL\t29355\tChicago Community Bank\tJune 27, 2002\tApril 9, 2008\tnone\tNaN\tNaN\n",
    "524\tConnecticut Bank of Commerce\tStamford\tCT\t19183\tHudson United Bank\tJune 26, 2002\tFebruary 14, 2012\tnone\tNaN\tNaN\n",
    "525\tNew Century Bank\tShelby Township\tMI\t34979\tNo Acquirer\tMarch 28, 2002\tMarch 18, 2005\tnone\tNaN\tNaN\n",
    "526\tNet 1st National Bank\tBoca Raton\tFL\t26652\tBank Leumi USA\tMarch 1, 2002\tApril 9, 2008\tnone\tNaN\tNaN\n",
    "527\tNextBank, NA\tPhoenix\tAZ\t22314\tNo Acquirer\tFebruary 7, 2002\tFebruary 5, 2015\tnone\tNaN\tNaN\n",
    "528\tOakwood Deposit Bank Co.\tOakwood\tOH\t8966\tThe State Bank & Trust Company\tFebruary 1, 2002\tOctober 25, 2012\tnone\tNaN\tNaN\n",
    "529\tBank of Sierra Blanca\tSierra Blanca\tTX\t22002\tThe Security State Bank of Pecos\tJanuary 18, 2002\tNovember 6, 2003\tnone\tNaN\tNaN\n",
    "530\tHamilton Bank, NAEn Espanol\tMiami\tFL\t24382\tIsrael Discount Bank of New York\tJanuary 11, 2002\tJune 5, 2012\tnone\tNaN\tNaN\n",
    "531\tSinclair National Bank\tGravette\tAR\t34248\tDelta Trust & Bank\tSeptember 7, 2001\tFebruary 10, 2004\tnone\tNaN\tNaN\n",
    "532\tSuperior Bank, FSB\tHinsdale\tIL\t32646\tSuperior Federal, FSB\tJuly 27, 2001\tAugust 19, 2014\tnone\tNaN\tNaN\n",
    "533\tMalta National Bank\tMalta\tOH\t6629\tNorth Valley Bank\tMay 3, 2001\tNovember 18, 2002\tnone\tNaN\tNaN\n",
    "534\tFirst Alliance Bank & Trust Co.\tManchester\tNH\t34264\tSouthern New Hampshire Bank & Trust\tFebruary 2, 2001\tFebruary 18, 2003\tnone\tNaN\tNaN\n",
    "535\tNational State Bank of Metropolis\tMetropolis\tIL\t3815\tBanterra Bank of Marion\tDecember 14, 2000\tMarch 17, 2005\tnone\tNaN\tNaN\n",
    "536\tBank of Honolulu\tHonolulu\tHI\t21029\tBank of the Orient\tOctober 13, 2000\tMarch 17, 2005\tnone\tNaN\tNaN\n",
    "537 rows × 10 columns\n",
    "\n",
    "dframe.columns.values\n",
    "array([u'Bank Name', u'City', u'ST', u'CERT', u'Acquiring Institution',\n",
    "       u'Closing Date', u'Updated Date', u'Loss Share Type',\n",
    "       u'Agreement Terminated', u'Termination Date'], dtype=object)\n",
    "#Next we'll learn about working with Excel files!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-daf5efccdf08>, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-5-daf5efccdf08>\"\u001b[1;36m, line \u001b[1;32m13\u001b[0m\n\u001b[1;33m    This is a test\tUnnamed: 1\tUnnamed: 2\u001b[0m\n\u001b[1;37m                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#Now we'll learn how to work with excel files\n",
    "\"\"\"\n",
    "IMPORTANT NOTE: NEED TO HAVE xlrd AND openpyxl INSTALLED!!!\n",
    "\"\"\"\n",
    "'\\nIMPORTANT NOTE: NEED TO HAVE xlrd AND openpyxl INSTALLED!!!\\n'\n",
    "import pandas as pd\n",
    "# Open the excel file as an object\n",
    "xlsfile = pd.ExcelFile('Lec_28_test.xlsx')\n",
    "# Parse the first sheet of the excel file and set as DataFrame\n",
    "dframe = xlsfile.parse('Sheet1')\n",
    "#Show!\n",
    "dframe\n",
    "This is a test\tUnnamed: 1\tUnnamed: 2\n",
    "0\t23\t6678\t456\n",
    "1\t234\t678\t456\n",
    "2\t234\t7\t345\n",
    "3\t34\t56\t234\n",
    "4\t5\t456\t4365\n",
    "#Now we know how to open various file types! Great!\n",
    "#Next well learn about various DataFrame Techniques!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
